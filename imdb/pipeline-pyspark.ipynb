{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2eb797-3622-422f-97df-95f6f4f454fb",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c3a4e-d01b-4874-908d-ec2d1cf22b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "from py_files.load_box_office_data import load_and_aggregate_box_office\n",
    "from py_files.add_remake_feature import create_remake_column\n",
    "from py_files.add_langoriginaltitle_feature import add_language_of_original_title\n",
    "from py_files.add_ENvsNonEN_feature import add_english_title_or_not\n",
    "from py_files.add_movie_genre_feature import add_movie_genre\n",
    "from py_files.df_processor_enrichment import df_processor_enrichment\n",
    "\n",
    "from py_files.df_model_prep import df_model_prep\n",
    "from py_files.d2v_embed import d2v_embed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "from  pyspark.sql.functions import input_file_name, substring, udf,col, lit, coalesce, when, regexp_replace, count\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n",
    "\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59816f3-b00d-4d73-bf8c-401c9a528c99",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7dcbe7-3de0-4f9d-b1f9-23a235d489cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "all_files = glob.glob(\"train*.csv\")\n",
    "\n",
    "print(f\"Found files: {', '.join(all_files)}\")\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"_c0\",IntegerType(),True) \\\n",
    "      .add(\"tconst\",StringType(),True) \\\n",
    "      .add(\"primaryTitle\",StringType(),True) \\\n",
    "      .add(\"originalTitle\",StringType(),True) \\\n",
    "      .add(\"startYear\",IntegerType(),True) \\\n",
    "      .add(\"endYear\",IntegerType(),True) \\\n",
    "      .add(\"runtimeMinutes\",IntegerType(),True) \\\n",
    "      .add(\"numVotes\",IntegerType(),True) \\\n",
    "      .add(\"label\",BooleanType(),True)\n",
    "\n",
    "# skip the header and define our own because the automatic detection doesn't go right\n",
    "n_skip_rows = 1\n",
    "row_rdd = spark.sparkContext \\\n",
    "    .textFile(\"train*.csv\") \\\n",
    "    .zipWithIndex() \\\n",
    "    .filter(lambda row: row[1] >= n_skip_rows) \\\n",
    "    .map(lambda row: row[0])\n",
    "\n",
    "training_data = spark.read.csv(row_rdd, schema=schema, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8291b2d-ad58-4477-9e9d-8cf717f95f0f",
   "metadata": {},
   "source": [
    "# Preprocessing of original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9711c-aa48-485b-9093-f142059703d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_titles(title):\n",
    "    return unicodedata.normalize('NFKD',title.lower()).encode('ascii', errors='ignore').decode('utf-8').replace(\" \", \"_\").replace(\"\\W\", \"\")\n",
    "\n",
    "udf_format_titles = udf(format_titles, StringType()) # if the function returns an int\n",
    "\n",
    "training_data.show()\n",
    "training_data = training_data.withColumn(\"primaryTitleFormatted\", lit(udf_format_titles('primaryTitle')))\n",
    "training_data = training_data.withColumn('Year', coalesce('startYear', 'endYear'))\n",
    "training_data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13628a1-7394-4a0f-bf00-8ea7ce5f8a26",
   "metadata": {},
   "source": [
    "## Preprocessing of exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5e9f-6bbc-4094-b30d-79eedc0e9613",
   "metadata": {},
   "source": [
    "### Oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec5f29-a1a8-4dbe-9d38-ea74c40891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscars = spark.read.csv(\"additional_data/oscars.csv\", header=True)\n",
    "oscars = oscars.na.drop(subset=[\"film\"])\n",
    "oscars = oscars.withColumn(\"film\", lit(udf_format_titles('film')))\n",
    "\n",
    "cond = [training_data.primaryTitleFormatted == oscars.film]\n",
    "oscar_noms = training_data.join(oscars, cond, 'inner').groupBy('tconst').count()\n",
    "oscar_wins = training_data.join(oscars, cond, 'inner').filter(col('winner') == True).groupBy('tconst').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68d611-2a1c-4afd-98bb-f537b4e2a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscar_noms.show()\n",
    "oscar_wins.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f1da1-6a79-4b57-9eb3-87796ce460e2",
   "metadata": {},
   "source": [
    "### Writer and Director data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549ed24-a788-4a2d-80b3-1e26ebbefd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find writers and directors per movie and combine the two\n",
    "written_and_directed = (writer_director_to_one_hot(\"writers\") + writer_director_to_one_hot(\"directors\")).fillna(0).astype(int).loc[df_preprocessed['tconst']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb61c28-a98e-49a3-ae69-6a505c193f84",
   "metadata": {},
   "source": [
    "### TMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb9dfd-13ae-4ecf-8a1e-90236bf4767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB = pd.read_csv(\"additional_data/TMDB.csv\")[[\"budget\", \"genres\", \"imdb_id\", \n",
    "                                                   \"original_language\", \"overview\", \n",
    "                                                   \"popularity\", \"production_companies\", \n",
    "                                                   \"tagline\", \"Keywords\", \"revenue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_list(dictionary):\n",
    "    try:\n",
    "        d = ast.literal_eval(dictionary)\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    return [i[\"name\"] for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff223907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB[\"genres\"] = df_TMDB[\"genres\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"Keywords\"] = df_TMDB[\"Keywords\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"production_companies\"] = df_TMDB[\"production_companies\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB = df_TMDB.set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f41eed",
   "metadata": {},
   "source": [
    "### Metacritic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"additional_data/Metacritic.csv\").drop(\"Unnamed: 0\", axis=1).set_index(\"movie\")\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: eval(x))\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: x[0] if x else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for faster merge\n",
    "df_TMDB[\"overview\"] = df_TMDB[\"overview\"].str.cat(df_meta[\"overview\"], join=\"outer\", na_rep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526bd3-364f-4db2-919f-1e9a9c90ef31",
   "metadata": {},
   "source": [
    "### Box Office data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab0f07-c114-4741-8ba1-5b162676582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_office_schema = StructType() \\\n",
    "      .add(\"Rank\",IntegerType(),True) \\\n",
    "      .add(\"Release Group\",StringType(),True) \\\n",
    "      .add(\"Worldwide\",StringType(),True) \\\n",
    "      .add(\"Domestic\",StringType(),True) \\\n",
    "      .add(\"Col_to_Drop1\",StringType(),True) \\\n",
    "      .add(\"Foreign\",StringType(),True) \\\n",
    "      .add(\"Col_to_Drop2\",StringType(),True)\n",
    "\n",
    "n_skip_rows = 1\n",
    "box_office_rdd = spark.sparkContext \\\n",
    "    .textFile(\"box_office_mojo/*.csv\") \\\n",
    "    .zipWithIndex() \\\n",
    "    .filter(lambda row: row[1] >= n_skip_rows) \\\n",
    "    .map(lambda row: row[0])\n",
    "\n",
    "df_box_office_mojo = spark.read.csv(box_office_rdd, schema=box_office_schema, header=False)\n",
    "\n",
    "# process the 'release group' (read movie title) in the same way as the formatted title\n",
    "df_box_office_mojo = df_box_office_mojo.withColumn(\"Release Group\", lit(udf_format_titles('Release Group')))\n",
    "\n",
    "# add the year of the box office file\n",
    "df_box_office_mojo = df_box_office_mojo.withColumn(\"year\", substring(input_file_name(), -8, 4).cast(IntegerType()))\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_box_office_mojo = df_box_office_mojo.drop(*('Col_to_Drop1', 'Col_to_Drop2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2446b69-5867-4d66-9df7-03da9d2559d4",
   "metadata": {},
   "source": [
    "# Adding of exogenous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46bee7-f2ac-4c41-ba16-8f62ae993999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "# df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "# df_incl_exog.info()\n",
    "# training_data = training_data.withColumnRenamed('tconst', 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dae00e-a724-4937-ab4b-b8f1c0057279",
   "metadata": {},
   "source": [
    "## add oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d5c22-fda8-4037-a984-c089c5e0c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.join(oscar_noms, ['tconst'], 'left').withColumnRenamed('count', 'oscar_noms')\n",
    "training_data = training_data.join(oscar_wins, ['tconst'], 'left').withColumnRenamed('count', 'oscar_wins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6caad7a-65a6-42e5-9d56-57550539430e",
   "metadata": {},
   "source": [
    "## add mojo box office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667716a-0aa2-494c-98af-bfdc45ee4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_box_office_values(column):\n",
    "    return when(column != '-', column).otherwise(lit(None))\n",
    "\n",
    "cond_mojo_merge = [training_data.primaryTitleFormatted == df_box_office_mojo['Release Group'], training_data.Year == df_box_office_mojo.year]\n",
    "\n",
    "training_data = training_data.join(df_box_office_mojo, cond_mojo_merge, 'left').drop(*('Release Group', 'year'))\n",
    "training_data = training_data.withColumn(\"Worldwide\", remove_missing_box_office_values(col(\"Worldwide\")))\n",
    "training_data = training_data.withColumn(\"Domestic\", remove_missing_box_office_values(col(\"Domestic\")))\n",
    "training_data = training_data.withColumn(\"Foreign\", remove_missing_box_office_values(col(\"Foreign\")))\n",
    "training_data = training_data.withColumn('Worldwide', regexp_replace('Worldwide', '[$,]', '').cast('double'))\n",
    "training_data = training_data.withColumn('Domestic', regexp_replace('Domestic', '[$,]', '').cast('double'))\n",
    "training_data = training_data.withColumn('Foreign', regexp_replace('Foreign', '[$,]', '').cast('double'))\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df971c9-ef59-4c29-9ab2-99396a2b2376",
   "metadata": {},
   "source": [
    "## add remake column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38866dfb-4664-4e21-91db-a15c00210d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.join(\n",
    "    training_data.groupBy(\"primaryTitle\").agg((count(\"*\")>1).cast(\"int\").alias(\"hasRemake\")),\n",
    "    on=\"primaryTitle\",\n",
    "    how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536fd42-e58b-4f89-a3d6-f6367c7ace74",
   "metadata": {},
   "source": [
    "## add title language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "433f4db5-5b7d-4cca-b78e-fc58a679dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the language of the original title, currently commented for training data usage and not wait 15 min every time\n",
    "# df_incl_exog = add_language_of_original_title(df_incl_exog)\n",
    "\n",
    "# df_added_lang = pd.read_csv('additional_data/df_added_lang.csv', index_col=0)\n",
    "# df_added_lang = df_added_lang.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "# df_incl_exog = df_incl_exog.join(df_added_lang['title_language'], how='left')\n",
    "\n",
    "added_lang_schema = StructType() \\\n",
    "      .add(\"_c0\",IntegerType(),True) \\\n",
    "      .add(\"tconst\",StringType(),True) \\\n",
    "      .add(\"primaryTitle\",StringType(),True) \\\n",
    "      .add(\"originalTitle\",StringType(),True) \\\n",
    "      .add(\"startYear\",IntegerType(),True) \\\n",
    "      .add(\"endYear\",IntegerType(),True) \\\n",
    "      .add(\"runtimeMinutes\",IntegerType(),True) \\\n",
    "      .add(\"numVotes\",IntegerType(),True) \\\n",
    "      .add(\"label\",BooleanType(),True) \\\n",
    "      .add(\"title_language\",StringType(),True) \\\n",
    "      .add(\"isEN\",BooleanType(),True) \n",
    "\n",
    "n_skip_rows = 1\n",
    "added_lang_rdd = spark.sparkContext \\\n",
    "    .textFile('additional_data/df_added_lang.csv') \\\n",
    "    .zipWithIndex() \\\n",
    "    .filter(lambda row: row[1] >= n_skip_rows) \\\n",
    "    .map(lambda row: row[0])\n",
    "\n",
    "df_added_lang = spark.read.csv(added_lang_rdd, schema=added_lang_schema, header=False)\n",
    "\n",
    "training_data = training_data.join(df_added_lang.select(['tconst', 'title_language']), on='tconst', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e08e1-082f-4c4d-9226-96037e800e78",
   "metadata": {},
   "source": [
    "## add whether title is English or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbbb9f93-740b-4665-8603-a9c01ae72d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicate_whether_language_is_english(column):\n",
    "    return when(column == 'en', True).otherwise(lit(False))\n",
    "\n",
    "training_data = training_data.withColumn(\"isEN\", indicate_whether_language_is_english(col(\"title_language\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eb5e6d2-55da-4e0b-a74f-8c3fe643c35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----+--------------------+---------+-------+--------------+--------+-----+---------------------+----------+----------+----+------------+-----------+-----------+---------+--------------+-----+\n",
      "|    tconst|        primaryTitle| _c0|       originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|primaryTitleFormatted|oscar_noms|oscar_wins|Rank|   Worldwide|   Domestic|    Foreign|hasRemake|title_language| isEN|\n",
      "+----------+--------------------+----+--------------------+---------+-------+--------------+--------+-----+---------------------+----------+----------+----+------------+-----------+-----------+---------+--------------+-----+\n",
      "| tt0063288|Be Sick... It's Free|1214|Il medico della m...|     1968|   null|            98|    null| true| be_sick..._it's_free|      null|      null|null|        null|       null|       null|        0|            it|false|\n",
      "| tt0912580|The Devil Came on...|5468|The Devil Came on...|     2007|   null|            88|    null| true| the_devil_came_on...|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt0081400|   Ráisé thé Titánic|1826|   Raise the Titanic|     1980|   null|           115|    null|false|    raise_the_titanic|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "|tt11809034|Rurouni Kenshin: ...|6034|Rurôni Kenshin: S...|     2021|   null|           138|    null| true| rurouni_kenshin:_...|      null|      null|  82| 3.6964978E7|       null|3.6964978E7|        0|            en| true|\n",
      "| tt0073582|            Deep Red|1573|      Profondo rosso|     1975|   null|           127|    null| true|             deep_red|      null|      null|null|        null|       null|       null|        0|            pt|false|\n",
      "| tt4307692|         Traumfrauen|8524|                null|     2015|   null|           109|    null|false|          traumfrauen|      null|      null|null|        null|       null|       null|        0|            de|false|\n",
      "| tt1307873|        The Big Bang|6278|        The Big Bang|     2010|   null|           101|    null|false|         the_big_bang|      null|      null|null|        null|       null|       null|        0|            tl|false|\n",
      "| tt2366806|The Day of the Li...|7565|                null|     2014|   null|            90|    null|false| the_day_of_the_li...|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt5890000|     Survival Family|9118|    Sabaibaru famirî|     null|   2016|           117|    null| true|      survival_family|      null|      null|null|        null|       null|       null|        0|            so|false|\n",
      "| tt0427229|   Failure to Launch|4843|                null|     2006|   null|            97|    null|false|    failure_to_launch|      null|      null|  43|1.30224158E8|8.8715192E7|4.1508966E7|        0|            fr|false|\n",
      "| tt2497980|       The Lookalike|7679|       The Lookalike|     2014|   null|           100|    null|false|        the_lookalike|      null|      null|null|        null|       null|       null|        0|            et|false|\n",
      "| tt1754029|The Crypt of Coun...|6949|Kutsal Damacana 3...|     2011|   null|            89|    null|false| the_crypt_of_coun...|      null|      null|null|        null|       null|       null|        0|            so|false|\n",
      "| tt0319524|         How to Deal|4279|                null|     2003|   null|           101|    null|false|          how_to_deal|      null|      null| 165| 1.4390329E7|1.4195227E7|   195102.0|        0|            en| true|\n",
      "| tt5894778| Lớúisé by thé Shớré|9120|                null|     null|   2016|            75|    null| true|  louise_by_the_shore|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt2566016|   The Laughing Mask|7717|   The Laughing Mask|     2014|   null|           101|    null|false|    the_laughing_mask|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt0037614|   The Corn Is Green| 383|   The Corn Is Green|     1945|   null|           115|    null| true|    the_corn_is_green|         2|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt2378191|The Haunting of H...|7585|                null|     2012|   null|            84|    null|false| the_haunting_of_h...|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt0025318|         It's a Gift| 137|         It's a Gift|     1934|   null|            68|    null| true|          it's_a_gift|      null|      null|null|        null|       null|       null|        0|            en| true|\n",
      "| tt4328934|            Taramani|8535|                null|     2017|   null|           150|    null| true|             taramani|      null|      null|null|        null|       null|       null|        0|            id|false|\n",
      "| tt0286009|      Les rois mages|4119|                null|     2001|   null|           102|    null|false|       les_rois_mages|      null|      null| 163|  1.170202E7|       null| 1.170202E7|        0|            fr|false|\n",
      "+----------+--------------------+----+--------------------+---------+-------+--------------+--------+-----+---------------------+----------+----------+----+------------+-----------+-----------+---------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474618a-1b2f-450f-b6fa-0d29c0e3f787",
   "metadata": {},
   "source": [
    "## add movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf82d3-11c4-4123-b32f-c18edcd62b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = add_movie_genre(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdede2-af9c-4016-9b83-21b412c94a03",
   "metadata": {},
   "source": [
    "## add writers and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91072814-513e-4703-bdc7-02b8fff1c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07d253-1413-4361-ac37-5e24d6f70aab",
   "metadata": {},
   "source": [
    "## add TMDB & Metacritic overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159932a5-a54d-4c12-bc65-7576145ecafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.merge(df_incl_exog, df_TMDB, how = \"left\", left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog[\"overview\"].str.len().sort_values().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a73f82-6734-4a3b-94b6-4002379ac243",
   "metadata": {},
   "source": [
    "## save dataframe with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beeae1-35dc-4c88-9b41-89f5c03f6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog.to_csv('df_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8d91",
   "metadata": {},
   "source": [
    "# Preparing data for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4fe2f",
   "metadata": {},
   "source": [
    "Convert non-numeric columns to numeric.\n",
    "We use Doc2Vec to embed each string column into n-by-128 array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('df_with_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_prepped = df_model_prep(train_df,'train')\n",
    "train_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model_prep function for demonstration purposes\n",
    "#\n",
    "# from py_files.d2v_embed import d2v_embed\n",
    "# import pandas as pd\n",
    "# import math\n",
    "\n",
    "# def df_model_prep(df, filename):\n",
    "    \n",
    "#     try:\n",
    "#         print(\"Looking for pre made file...\")\n",
    "#         return pd.read_csv(f\"{filename}_df_with_features_fully_processed_read_for_model.csv\", index_col = 0)\n",
    "#     except:\n",
    "#         print(\"No file found, creating a new one\")\n",
    "    \n",
    "#     prim_title_df = d2v_embed(df['primaryTitle'])\n",
    "#     orig_title_df = d2v_embed(df['originalTitle'])\n",
    "#     prim_title_formatted_df = d2v_embed(df['primaryTitleFormatted'])\n",
    "#     title_formatted_df = d2v_embed(df['titleFormatted'])\n",
    "#     genres_df = d2v_embed(df['genres'])\n",
    "\n",
    "#     # just encode languages into ints for this column\n",
    "#     df['title_language'] = pd.factorize(df['title_language'])[0]\n",
    "\n",
    "#     df.drop(columns = df.select_dtypes(include='object').columns, inplace=True)\n",
    "\n",
    "#     # dealing with (some) nan values\n",
    "#     for index, row in df.iterrows():\n",
    "#         # For missing startYear or endYear entries, insert the other, if it exists.\n",
    "#         if math.isnan(row['startYear']):\n",
    "#             if not math.isnan(row['endYear']):\n",
    "#                 df.at[index,'startYear']=df.at[index,'endYear']\n",
    "#         if math.isnan(row['endYear']):\n",
    "#             if not math.isnan(row['startYear']):\n",
    "#                 df.at[index,'endYear']=df.at[index,'startYear']\n",
    "\n",
    "#         # For missing oscar_noms and oscar_wins, insert 0\n",
    "#         if math.isnan(row['oscar_noms']):\n",
    "#             df.at[index,'oscar_noms'] = 0\n",
    "#         if math.isnan(row['oscar_wins']):\n",
    "#             df.at[index,'oscar_wins'] = 0\n",
    "\n",
    "#     df['numVotes'] = df['numVotes'].fillna(df['numVotes'].mean(skipna=True))\n",
    "#     df['runtimeMinutes'] = df['runtimeMinutes'].fillna(df['runtimeMinutes'].mean(skipna=True))\n",
    "    \n",
    "#     df['title_language'] = pd.factorize(df['title_language'])[0]\n",
    "    \n",
    "#     df = df.join(prim_title_df)\n",
    "#     df = df.join(orig_title_df)\n",
    "#     df = df.join(prim_title_formatted_df)\n",
    "#     df = df.join(title_formatted_df)\n",
    "#     df = df.join(genres_df)\n",
    "    \n",
    "#     df.to_csv(f\"{filename}_df_with_features_fully_processed_read_for_model.csv\")\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2v_embed function for demonstration purposes\n",
    "# \n",
    "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import multiprocessing as mp\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import math\n",
    "\n",
    "# def d2v_embed(df_col, max_epochs = 100, vec_size = 128, alpha = 0.025):\n",
    "    \n",
    "#     df_col = df_col.fillna(\" \")\n",
    "#     df_col = df_col.str.lower()\\\n",
    "#                    .str.normalize('NFKD')\\\n",
    "#                    .str.encode('ascii', errors='ignore')\\\n",
    "#                    .str.decode('utf-8')\\\n",
    "#                    .str.replace(\"\\W\", \" \", regex=True)\n",
    "    \n",
    "#     tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(df_col)]\n",
    "\n",
    "#     model = Doc2Vec(vector_size=vec_size,\n",
    "#                     alpha=alpha, \n",
    "#                     min_alpha=0.00025,\n",
    "#                     min_count=1,\n",
    "#                     dm =1,\n",
    "#                     workers = mp.cpu_count())\n",
    "  \n",
    "#     model.build_vocab(tagged_data)\n",
    "\n",
    "#     for epoch in tqdm(range(max_epochs)):\n",
    "#     #     print('iteration {0}'.format(epoch))\n",
    "#         model.train(tagged_data,\n",
    "#                     total_examples=model.corpus_count,\n",
    "#                     epochs=model.epochs)\n",
    "#         # decrease the learning rate\n",
    "#         model.alpha -= 0.0002\n",
    "#         # fix the learning rate, no decay\n",
    "#         model.min_alpha = model.alpha\n",
    "    \n",
    "#     # save model\n",
    "#     model.save(f\"doc2vec_model_{df_col.name}.model\")\n",
    "    \n",
    "#     #return df with doc embeddings\n",
    "#     return pd.DataFrame([model.docvecs[i] for i in range(len(df_col))], \n",
    "#                         index = df_col.index,\n",
    "#                         columns = [f\"{df_col.name}_{i}\" for i in range(vec_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f07bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processor_enrichment function for demonstration purposes\n",
    "# \n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from itertools import groupby\n",
    "\n",
    "# from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "# from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "# from py_files.load_box_office_data import load_and_aggregate_box_office\n",
    "# from py_files.add_remake_feature import create_remake_column\n",
    "# from py_files.add_langoriginaltitle_feature import add_language_of_original_title\n",
    "# from py_files.add_ENvsNonEN_feature import add_english_title_or_not\n",
    "# from py_files.add_movie_genre_feature import add_movie_genre\n",
    "\n",
    "# from py_files.d2v_embed import d2v_embed\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import math\n",
    "\n",
    "# def df_processor_enrichment(filename):\n",
    "    \n",
    "#     try:\n",
    "#         print(\"Looking for pre made file...\")\n",
    "#         return pd.read_csv(f\"{filename}_df_with_features.csv\", index_col = 0)\n",
    "#     except:\n",
    "#         print(\"File not found, creating a new one..\")\n",
    "              \n",
    "#     df_original = pd.read_csv(filename, index_col=0)\n",
    "#     # df_original.head()\n",
    "\n",
    "#     # start the preprocessing\n",
    "#     df_preprocessed = df_original.replace(\"\\\\N\", np.nan)\n",
    "#     df_preprocessed[\"primaryTitleFormatted\"] = df_preprocessed[\"primaryTitle\"].str.lower()\\\n",
    "#                                                                               .str.normalize('NFKD')\\\n",
    "#                                                                               .str.encode('ascii', errors='ignore')\\\n",
    "#                                                                               .str.decode('utf-8')\\\n",
    "#                                                                               .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                                                               .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "#     # merge endYear into beginYear when beginYear is not available --> rename Year\n",
    "#     df_preprocessed = merge_start_end_year(df_preprocessed)\n",
    "\n",
    "#     # set the datatypes of the dataframe correctly\n",
    "#     df_preprocessed['Year'] = df_preprocessed['Year'].astype(int)\n",
    "#     df_preprocessed['runtimeMinutes'] = df_preprocessed['runtimeMinutes'].astype(float)\n",
    "\n",
    "#     # df_preprocessed.info()\n",
    "\n",
    "\n",
    "#     oscars = pd.read_csv(\"additional_data/oscars.csv\")\n",
    "\n",
    "#     oscars[\"film\"] = oscars[\"film\"].str.lower()\\\n",
    "#                                    .str.normalize('NFKD')\\\n",
    "#                                    .str.encode('ascii', errors='ignore')\\\n",
    "#                                    .str.decode('utf-8')\\\n",
    "#                                    .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                    .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "#     # Counting oscar nominations and wins per movie\n",
    "#     oscar_noms = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].count()\n",
    "#     oscar_wins = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].sum()\n",
    "\n",
    "\n",
    "#     # Find writers and directors per movie and combine the two\n",
    "#     written_and_directed = (writer_director_to_one_hot(\"writers\") + writer_director_to_one_hot(\"directors\")).fillna(0).astype(int).loc[df_preprocessed['tconst']]\n",
    "\n",
    "\n",
    "#     df_box_office_mojo = load_and_aggregate_box_office()\n",
    "\n",
    "#     # process the 'release group' (read movie title) in the same way as the formatted title\n",
    "#     df_box_office_mojo[\"Release Group\"] = df_box_office_mojo[\"Release Group\"].str.lower()\\\n",
    "#                                            .str.normalize('NFKD')\\\n",
    "#                                            .str.encode('ascii', errors='ignore')\\\n",
    "#                                            .str.decode('utf-8')\\\n",
    "#                                            .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                            .str.replace(\"\\W\", \"\", regex=True)\n",
    "#     df_box_office_mojo.drop(['%', '%.1'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#     df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "#     df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "#     # df_incl_exog.info()\n",
    "\n",
    "\n",
    "#     df_incl_exog[\"oscar_noms\"] = oscar_noms\n",
    "#     df_incl_exog[\"oscar_wins\"] = oscar_wins\n",
    "\n",
    "#     df_incl_exog = df_incl_exog.reset_index().merge(df_box_office_mojo, left_on=['primaryTitleFormatted', 'Year'], right_on=['Release Group', 'year'], how=\"left\").set_index('id')\n",
    "#     df_incl_exog.drop(['Release Group', 'year'], axis=1, inplace=True)\n",
    "\n",
    "#     df_incl_exog.loc[df_incl_exog['Worldwide'] == '-', 'Worldwide'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Domestic'] == '-', 'Domestic'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Foreign'] == '-', 'Foreign'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'] = df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "#     df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'] = df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "#     df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'] = df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "\n",
    "\n",
    "#     df_incl_exog = create_remake_column(df_incl_exog)\n",
    "\n",
    "#     # # add the language of the original title, currently commented for training data usage and not wait 15 min every time\n",
    "#     # df_incl_exog = add_language_of_original_title(df_incl_exog)\n",
    "\n",
    "#     df_added_lang = pd.read_csv('additional_data/df_added_lang.csv', index_col=0)\n",
    "#     df_added_lang = df_added_lang.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "#     df_incl_exog = df_incl_exog.join(df_added_lang['title_language'], how='left')\n",
    "\n",
    "#     df_incl_exog = add_english_title_or_not(df_incl_exog)\n",
    "#     df_incl_exog = add_movie_genre(df_incl_exog)\n",
    "#     df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T\n",
    "#     df_incl_exog.to_csv(f\"{filename}_df_with_features.csv\")\n",
    "    \n",
    "#     return df_incl_exog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c43d4-36ac-4082-a627-22f2f6e2ef5b",
   "metadata": {},
   "source": [
    "# Evaluating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cfad8-1582-4616-9bf3-677c07c39df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                                learning_rate=0.01,\n",
    "                                num_iterations=1000,\n",
    "                                feature_fraction=0.8,\n",
    "                                verbosity=1,\n",
    "                                random_state=17)\n",
    "model_lgbm.fit(train_df_prepped.loc[:, train_df_prepped.columns != 'label'],\n",
    "              train_df_prepped['label'],\n",
    "              eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9e8f9-2472-44bb-a561-16b23cfe4c63",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ba9ca",
   "metadata": {},
   "source": [
    "## Add and process train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df_processor_enrichment('validation_hidden.csv')\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_prepped = df_model_prep(valid_df, 'valid')\n",
    "valid_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_processor_enrichment('test_hidden.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_prepped = df_model_prep(test_df, 'test')\n",
    "test_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8259cc-1bc6-4447-8d9e-7cf00d9bc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_lgbm = model_lgbm.predict(valid_df_prepped)\n",
    "test_preds_lgbm = model_lgbm.predict(test_df_prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in val_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in test_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
