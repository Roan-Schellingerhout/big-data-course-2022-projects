{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2eb797-3622-422f-97df-95f6f4f454fb",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8c3a4e-d01b-4874-908d-ec2d1cf22b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "from py_files.load_box_office_data import load_and_aggregate_box_office\n",
    "from py_files.add_remake_feature import create_remake_column\n",
    "from py_files.add_langoriginaltitle_feature import add_language_of_original_title\n",
    "from py_files.add_ENvsNonEN_feature import add_english_title_or_not\n",
    "from py_files.add_movie_genre_feature import add_movie_genre\n",
    "from py_files.df_processor_enrichment import df_processor_enrichment\n",
    "\n",
    "from py_files.df_model_prep import df_model_prep\n",
    "from py_files.d2v_embed import d2v_embed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59816f3-b00d-4d73-bf8c-401c9a528c99",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f7dcbe7-3de0-4f9d-b1f9-23a235d489cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: train-8.csv, train-2.csv, train-7.csv, train-5.csv, train-3.csv, train-4.csv, train-1.csv, train-6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from py_files.load_original_data import load_original_data\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "all_files = glob.glob(\"train*.csv\")\n",
    "\n",
    "print(f\"Found files: {', '.join(all_files)}\")\n",
    "\n",
    " # Header: , tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes, label\n",
    "\n",
    "schema = StructType() \\\n",
    "      .add(\"_c0\",IntegerType(),True) \\\n",
    "      .add(\"tconst\",StringType(),True) \\\n",
    "      .add(\"primaryTitle\",StringType(),True) \\\n",
    "      .add(\"originalTitle\",StringType(),True) \\\n",
    "      .add(\"startYear\",IntegerType(),True) \\\n",
    "      .add(\"endYear\",IntegerType(),True) \\\n",
    "      .add(\"runtimeMinutes\",IntegerType(),True) \\\n",
    "      .add(\"numVotes\",IntegerType(),True) \\\n",
    "      .add(\"label\",BooleanType(),True)\n",
    "\n",
    "\n",
    "n_skip_rows = 1\n",
    "row_rdd = spark.sparkContext \\\n",
    "    .textFile(\"train*.csv\") \\\n",
    "    .zipWithIndex() \\\n",
    "    .filter(lambda row: row[1] >= n_skip_rows) \\\n",
    "    .map(lambda row: row[0])\n",
    "# df = spark_session.read.csv(row_rdd, ...)\n",
    "\n",
    "training_data = spark.read.csv(row_rdd, schema=schema, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8291b2d-ad58-4477-9e9d-8cf717f95f0f",
   "metadata": {},
   "source": [
    "# Preprocessing of original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bae9711c-aa48-485b-9093-f142059703d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
      "|_c0|   tconst|        primaryTitle|       originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|\n",
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
      "|  4|tt0010600|            The Doll|           Die Puppe|     1919|   null|            66|    null| true|\n",
      "|  7|tt0011841|       Way Down East|       Way Down East|     1920|   null|           145|    null| true|\n",
      "|  9|tt0012494|             Déstiny|        Der müde Tod|     1921|   null|            97|    null| true|\n",
      "| 25|tt0015163|       The Navigator|       The Navigator|     1924|   null|            59|    null| true|\n",
      "| 38|tt0016220|The Phantom of th...|The Phantom of th...|     1925|   null|            93|    null| true|\n",
      "| 42|tt0016630|     Báttling Bútlér|     Battling Butler|     1926|   null|            77|    null| true|\n",
      "| 81|tt0021015|Juno and the Paycock|                null|     1929|   null|            85|    null|false|\n",
      "|118|tt0023973|Thé Éáglé ánd thé...|                null|     1933|   null|            73|    null| true|\n",
      "|119|tt0023986| Émplớyéés' Éntráncé|                null|     1933|   null|            75|    null| true|\n",
      "|123|tt0024184|   The Invisible Man|   The Invisible Man|     1933|   null|            71|    null| true|\n",
      "|125|tt0024216|           King Kong|           King Kong|     1933|   null|           100|    null| true|\n",
      "|135|tt0025028|               Dames|                null|     1934|   null|            91|    null| true|\n",
      "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|     1936|   null|            80|    null| true|\n",
      "|180|tt0028333|          Swing Timé|                null|     1936|   null|           103|    null| true|\n",
      "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|     1938|   null|            96|    null| true|\n",
      "|222|tt0031143|The Cat and the C...|                null|     1939|   null|            72|    null| true|\n",
      "|231|tt0031385|  Goodbye, Mr. Chips|                null|     1939|   null|           114|    null| true|\n",
      "|239|tt0031647|            Midnight|                null|     1939|   null|            94|    null| true|\n",
      "|242|tt0031762|Only Angels Have ...|                null|     1939|   null|           121|    null| true|\n",
      "|253|tt0032156|The Story of the ...|  Zangiku monogatari|     1939|   null|           143|    null| true|\n",
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+---------------------+----+\n",
      "|_c0|   tconst|        primaryTitle|       originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|primaryTitleFormatted|Year|\n",
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+---------------------+----+\n",
      "|  4|tt0010600|            The Doll|           Die Puppe|     1919|   null|            66|    null| true|             the_doll|1919|\n",
      "|  7|tt0011841|       Way Down East|       Way Down East|     1920|   null|           145|    null| true|        way_down_east|1920|\n",
      "|  9|tt0012494|             Déstiny|        Der müde Tod|     1921|   null|            97|    null| true|              destiny|1921|\n",
      "| 25|tt0015163|       The Navigator|       The Navigator|     1924|   null|            59|    null| true|        the_navigator|1924|\n",
      "| 38|tt0016220|The Phantom of th...|The Phantom of th...|     1925|   null|            93|    null| true| the_phantom_of_th...|1925|\n",
      "| 42|tt0016630|     Báttling Bútlér|     Battling Butler|     1926|   null|            77|    null| true|      battling_butler|1926|\n",
      "| 81|tt0021015|Juno and the Paycock|                null|     1929|   null|            85|    null|false| juno_and_the_paycock|1929|\n",
      "|118|tt0023973|Thé Éáglé ánd thé...|                null|     1933|   null|            73|    null| true| the_eagle_and_the...|1933|\n",
      "|119|tt0023986| Émplớyéés' Éntráncé|                null|     1933|   null|            75|    null| true|  employees'_entrance|1933|\n",
      "|123|tt0024184|   The Invisible Man|   The Invisible Man|     1933|   null|            71|    null| true|    the_invisible_man|1933|\n",
      "|125|tt0024216|           King Kong|           King Kong|     1933|   null|           100|    null| true|            king_kong|1933|\n",
      "|135|tt0025028|               Dames|                null|     1934|   null|            91|    null| true|                dames|1934|\n",
      "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|     1936|   null|            80|    null| true| the_crime_of_mons...|1936|\n",
      "|180|tt0028333|          Swing Timé|                null|     1936|   null|           103|    null| true|           swing_time|1936|\n",
      "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|     1938|   null|            96|    null| true|    the_lady_vanishes|1938|\n",
      "|222|tt0031143|The Cat and the C...|                null|     1939|   null|            72|    null| true| the_cat_and_the_c...|1939|\n",
      "|231|tt0031385|  Goodbye, Mr. Chips|                null|     1939|   null|           114|    null| true|   goodbye,_mr._chips|1939|\n",
      "|239|tt0031647|            Midnight|                null|     1939|   null|            94|    null| true|             midnight|1939|\n",
      "|242|tt0031762|Only Angels Have ...|                null|     1939|   null|           121|    null| true| only_angels_have_...|1939|\n",
      "|253|tt0032156|The Story of the ...|  Zangiku monogatari|     1939|   null|           143|    null| true| the_story_of_the_...|1939|\n",
      "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+---------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf,col, lit, coalesce\n",
    "import unicodedata\n",
    "def format_titles(title):\n",
    "    return unicodedata.normalize('NFKD',title.lower()).encode('ascii', errors='ignore').decode('utf-8').replace(\" \", \"_\").replace(\"\\W\", \"\")\n",
    "\n",
    "# def merge_start_end_year(startyear, endyear):\n",
    "#     df_['Year'] = df_['startYear'].fillna(df_['endYear'])\n",
    "#     return df_\n",
    "\n",
    "udf_format_titles = udf(format_titles, StringType()) # if the function returns an int\n",
    "\n",
    "training_data.show()\n",
    "training_data = training_data.withColumn(\"primaryTitleFormatted\", lit(udf_format_titles('primaryTitle')))\n",
    "training_data = training_data.withColumn('Year', coalesce('startYear', 'endYear'))\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13628a1-7394-4a0f-bf00-8ea7ce5f8a26",
   "metadata": {},
   "source": [
    "## Preprocessing of exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5e9f-6bbc-4094-b30d-79eedc0e9613",
   "metadata": {},
   "source": [
    "### Oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec5f29-a1a8-4dbe-9d38-ea74c40891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscars = pd.read_csv(\"additional_data/oscars.csv\")\n",
    "\n",
    "oscars[\"film\"] = oscars[\"film\"].str.lower()\\\n",
    "                               .str.normalize('NFKD')\\\n",
    "                               .str.encode('ascii', errors='ignore')\\\n",
    "                               .str.decode('utf-8')\\\n",
    "                               .str.replace(\" \", \"_\", regex=True)\\\n",
    "                               .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "# Counting oscar nominations and wins per movie\n",
    "oscar_noms = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].count()\n",
    "oscar_wins = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f1da1-6a79-4b57-9eb3-87796ce460e2",
   "metadata": {},
   "source": [
    "### Writer and Director data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3549ed24-a788-4a2d-80b3-1e26ebbefd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find writers and directors per movie and combine the two\n",
    "written_and_directed = (writer_director_to_one_hot(\"writers\") + writer_director_to_one_hot(\"directors\")).fillna(0).astype(int).loc[df_preprocessed['tconst']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb61c28-a98e-49a3-ae69-6a505c193f84",
   "metadata": {},
   "source": [
    "### TMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb9dfd-13ae-4ecf-8a1e-90236bf4767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB = pd.read_csv(\"additional_data/TMDB.csv\")[[\"budget\", \"genres\", \"imdb_id\", \n",
    "                                                   \"original_language\", \"overview\", \n",
    "                                                   \"popularity\", \"production_companies\", \n",
    "                                                   \"tagline\", \"Keywords\", \"revenue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_list(dictionary):\n",
    "    try:\n",
    "        d = ast.literal_eval(dictionary)\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    return [i[\"name\"] for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff223907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB[\"genres\"] = df_TMDB[\"genres\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"Keywords\"] = df_TMDB[\"Keywords\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"production_companies\"] = df_TMDB[\"production_companies\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB = df_TMDB.set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f41eed",
   "metadata": {},
   "source": [
    "### Metacritic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"additional_data/Metacritic.csv\").drop(\"Unnamed: 0\", axis=1).set_index(\"movie\")\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: eval(x))\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: x[0] if x else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for faster merge\n",
    "df_TMDB[\"overview\"] = df_TMDB[\"overview\"].str.cat(df_meta[\"overview\"], join=\"outer\", na_rep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526bd3-364f-4db2-919f-1e9a9c90ef31",
   "metadata": {},
   "source": [
    "### Box Office data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab0f07-c114-4741-8ba1-5b162676582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_office_mojo = load_and_aggregate_box_office()\n",
    "\n",
    "# process the 'release group' (read movie title) in the same way as the formatted title\n",
    "df_box_office_mojo[\"Release Group\"] = df_box_office_mojo[\"Release Group\"].str.lower()\\\n",
    "                                       .str.normalize('NFKD')\\\n",
    "                                       .str.encode('ascii', errors='ignore')\\\n",
    "                                       .str.decode('utf-8')\\\n",
    "                                       .str.replace(\" \", \"_\", regex=True)\\\n",
    "                                       .str.replace(\"\\W\", \"\", regex=True)\n",
    "df_box_office_mojo.drop(['%', '%.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2446b69-5867-4d66-9df7-03da9d2559d4",
   "metadata": {},
   "source": [
    "# Adding of exogenous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46bee7-f2ac-4c41-ba16-8f62ae993999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "df_incl_exog.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dae00e-a724-4937-ab4b-b8f1c0057279",
   "metadata": {},
   "source": [
    "## add oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d5c22-fda8-4037-a984-c089c5e0c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog[\"oscar_noms\"] = oscar_noms\n",
    "df_incl_exog[\"oscar_wins\"] = oscar_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6caad7a-65a6-42e5-9d56-57550539430e",
   "metadata": {},
   "source": [
    "## add mojo box office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667716a-0aa2-494c-98af-bfdc45ee4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = df_incl_exog.reset_index().merge(df_box_office_mojo, left_on=['primaryTitleFormatted', 'Year'], right_on=['Release Group', 'year'], how=\"left\").set_index('id')\n",
    "df_incl_exog.drop(['Release Group', 'year'], axis=1, inplace=True)\n",
    "\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'] == '-', 'Worldwide'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'] == '-', 'Domestic'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'] == '-', 'Foreign'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'] = df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'] = df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'] = df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'].apply(lambda x: float(x.replace('$', '').replace(',', '')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df971c9-ef59-4c29-9ab2-99396a2b2376",
   "metadata": {},
   "source": [
    "## add remake column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38866dfb-4664-4e21-91db-a15c00210d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = create_remake_column(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536fd42-e58b-4f89-a3d6-f6367c7ace74",
   "metadata": {},
   "source": [
    "## add title language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f4db5-5b7d-4cca-b78e-fc58a679dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the language of the original title, currently commented for training data usage and not wait 15 min every time\n",
    "# df_incl_exog = add_language_of_original_title(df_incl_exog)\n",
    "\n",
    "df_added_lang = pd.read_csv('additional_data/df_added_lang.csv', index_col=0)\n",
    "df_added_lang = df_added_lang.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "df_incl_exog = df_incl_exog.join(df_added_lang['title_language'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e08e1-082f-4c4d-9226-96037e800e78",
   "metadata": {},
   "source": [
    "## add whether title is English or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb9f93-740b-4665-8603-a9c01ae72d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = add_english_title_or_not(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474618a-1b2f-450f-b6fa-0d29c0e3f787",
   "metadata": {},
   "source": [
    "## add movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf82d3-11c4-4123-b32f-c18edcd62b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = add_movie_genre(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdede2-af9c-4016-9b83-21b412c94a03",
   "metadata": {},
   "source": [
    "## add writers and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91072814-513e-4703-bdc7-02b8fff1c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07d253-1413-4361-ac37-5e24d6f70aab",
   "metadata": {},
   "source": [
    "## add TMDB & Metacritic overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159932a5-a54d-4c12-bc65-7576145ecafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.merge(df_incl_exog, df_TMDB, how = \"left\", left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog[\"overview\"].str.len().sort_values().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a73f82-6734-4a3b-94b6-4002379ac243",
   "metadata": {},
   "source": [
    "## save dataframe with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beeae1-35dc-4c88-9b41-89f5c03f6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog.to_csv('df_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8d91",
   "metadata": {},
   "source": [
    "# Preparing data for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4fe2f",
   "metadata": {},
   "source": [
    "Convert non-numeric columns to numeric.\n",
    "We use Doc2Vec to embed each string column into n-by-128 array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('df_with_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_prepped = df_model_prep(train_df,'train')\n",
    "train_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model_prep function for demonstration purposes\n",
    "#\n",
    "# from py_files.d2v_embed import d2v_embed\n",
    "# import pandas as pd\n",
    "# import math\n",
    "\n",
    "# def df_model_prep(df, filename):\n",
    "    \n",
    "#     try:\n",
    "#         print(\"Looking for pre made file...\")\n",
    "#         return pd.read_csv(f\"{filename}_df_with_features_fully_processed_read_for_model.csv\", index_col = 0)\n",
    "#     except:\n",
    "#         print(\"No file found, creating a new one\")\n",
    "    \n",
    "#     prim_title_df = d2v_embed(df['primaryTitle'])\n",
    "#     orig_title_df = d2v_embed(df['originalTitle'])\n",
    "#     prim_title_formatted_df = d2v_embed(df['primaryTitleFormatted'])\n",
    "#     title_formatted_df = d2v_embed(df['titleFormatted'])\n",
    "#     genres_df = d2v_embed(df['genres'])\n",
    "\n",
    "#     # just encode languages into ints for this column\n",
    "#     df['title_language'] = pd.factorize(df['title_language'])[0]\n",
    "\n",
    "#     df.drop(columns = df.select_dtypes(include='object').columns, inplace=True)\n",
    "\n",
    "#     # dealing with (some) nan values\n",
    "#     for index, row in df.iterrows():\n",
    "#         # For missing startYear or endYear entries, insert the other, if it exists.\n",
    "#         if math.isnan(row['startYear']):\n",
    "#             if not math.isnan(row['endYear']):\n",
    "#                 df.at[index,'startYear']=df.at[index,'endYear']\n",
    "#         if math.isnan(row['endYear']):\n",
    "#             if not math.isnan(row['startYear']):\n",
    "#                 df.at[index,'endYear']=df.at[index,'startYear']\n",
    "\n",
    "#         # For missing oscar_noms and oscar_wins, insert 0\n",
    "#         if math.isnan(row['oscar_noms']):\n",
    "#             df.at[index,'oscar_noms'] = 0\n",
    "#         if math.isnan(row['oscar_wins']):\n",
    "#             df.at[index,'oscar_wins'] = 0\n",
    "\n",
    "#     df['numVotes'] = df['numVotes'].fillna(df['numVotes'].mean(skipna=True))\n",
    "#     df['runtimeMinutes'] = df['runtimeMinutes'].fillna(df['runtimeMinutes'].mean(skipna=True))\n",
    "    \n",
    "#     df['title_language'] = pd.factorize(df['title_language'])[0]\n",
    "    \n",
    "#     df = df.join(prim_title_df)\n",
    "#     df = df.join(orig_title_df)\n",
    "#     df = df.join(prim_title_formatted_df)\n",
    "#     df = df.join(title_formatted_df)\n",
    "#     df = df.join(genres_df)\n",
    "    \n",
    "#     df.to_csv(f\"{filename}_df_with_features_fully_processed_read_for_model.csv\")\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2v_embed function for demonstration purposes\n",
    "# \n",
    "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import multiprocessing as mp\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import math\n",
    "\n",
    "# def d2v_embed(df_col, max_epochs = 100, vec_size = 128, alpha = 0.025):\n",
    "    \n",
    "#     df_col = df_col.fillna(\" \")\n",
    "#     df_col = df_col.str.lower()\\\n",
    "#                    .str.normalize('NFKD')\\\n",
    "#                    .str.encode('ascii', errors='ignore')\\\n",
    "#                    .str.decode('utf-8')\\\n",
    "#                    .str.replace(\"\\W\", \" \", regex=True)\n",
    "    \n",
    "#     tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(df_col)]\n",
    "\n",
    "#     model = Doc2Vec(vector_size=vec_size,\n",
    "#                     alpha=alpha, \n",
    "#                     min_alpha=0.00025,\n",
    "#                     min_count=1,\n",
    "#                     dm =1,\n",
    "#                     workers = mp.cpu_count())\n",
    "  \n",
    "#     model.build_vocab(tagged_data)\n",
    "\n",
    "#     for epoch in tqdm(range(max_epochs)):\n",
    "#     #     print('iteration {0}'.format(epoch))\n",
    "#         model.train(tagged_data,\n",
    "#                     total_examples=model.corpus_count,\n",
    "#                     epochs=model.epochs)\n",
    "#         # decrease the learning rate\n",
    "#         model.alpha -= 0.0002\n",
    "#         # fix the learning rate, no decay\n",
    "#         model.min_alpha = model.alpha\n",
    "    \n",
    "#     # save model\n",
    "#     model.save(f\"doc2vec_model_{df_col.name}.model\")\n",
    "    \n",
    "#     #return df with doc embeddings\n",
    "#     return pd.DataFrame([model.docvecs[i] for i in range(len(df_col))], \n",
    "#                         index = df_col.index,\n",
    "#                         columns = [f\"{df_col.name}_{i}\" for i in range(vec_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f07bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processor_enrichment function for demonstration purposes\n",
    "# \n",
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from itertools import groupby\n",
    "\n",
    "# from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "# from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "# from py_files.load_box_office_data import load_and_aggregate_box_office\n",
    "# from py_files.add_remake_feature import create_remake_column\n",
    "# from py_files.add_langoriginaltitle_feature import add_language_of_original_title\n",
    "# from py_files.add_ENvsNonEN_feature import add_english_title_or_not\n",
    "# from py_files.add_movie_genre_feature import add_movie_genre\n",
    "\n",
    "# from py_files.d2v_embed import d2v_embed\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import math\n",
    "\n",
    "# def df_processor_enrichment(filename):\n",
    "    \n",
    "#     try:\n",
    "#         print(\"Looking for pre made file...\")\n",
    "#         return pd.read_csv(f\"{filename}_df_with_features.csv\", index_col = 0)\n",
    "#     except:\n",
    "#         print(\"File not found, creating a new one..\")\n",
    "              \n",
    "#     df_original = pd.read_csv(filename, index_col=0)\n",
    "#     # df_original.head()\n",
    "\n",
    "#     # start the preprocessing\n",
    "#     df_preprocessed = df_original.replace(\"\\\\N\", np.nan)\n",
    "#     df_preprocessed[\"primaryTitleFormatted\"] = df_preprocessed[\"primaryTitle\"].str.lower()\\\n",
    "#                                                                               .str.normalize('NFKD')\\\n",
    "#                                                                               .str.encode('ascii', errors='ignore')\\\n",
    "#                                                                               .str.decode('utf-8')\\\n",
    "#                                                                               .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                                                               .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "#     # merge endYear into beginYear when beginYear is not available --> rename Year\n",
    "#     df_preprocessed = merge_start_end_year(df_preprocessed)\n",
    "\n",
    "#     # set the datatypes of the dataframe correctly\n",
    "#     df_preprocessed['Year'] = df_preprocessed['Year'].astype(int)\n",
    "#     df_preprocessed['runtimeMinutes'] = df_preprocessed['runtimeMinutes'].astype(float)\n",
    "\n",
    "#     # df_preprocessed.info()\n",
    "\n",
    "\n",
    "#     oscars = pd.read_csv(\"additional_data/oscars.csv\")\n",
    "\n",
    "#     oscars[\"film\"] = oscars[\"film\"].str.lower()\\\n",
    "#                                    .str.normalize('NFKD')\\\n",
    "#                                    .str.encode('ascii', errors='ignore')\\\n",
    "#                                    .str.decode('utf-8')\\\n",
    "#                                    .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                    .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "#     # Counting oscar nominations and wins per movie\n",
    "#     oscar_noms = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].count()\n",
    "#     oscar_wins = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].sum()\n",
    "\n",
    "\n",
    "#     # Find writers and directors per movie and combine the two\n",
    "#     written_and_directed = (writer_director_to_one_hot(\"writers\") + writer_director_to_one_hot(\"directors\")).fillna(0).astype(int).loc[df_preprocessed['tconst']]\n",
    "\n",
    "\n",
    "#     df_box_office_mojo = load_and_aggregate_box_office()\n",
    "\n",
    "#     # process the 'release group' (read movie title) in the same way as the formatted title\n",
    "#     df_box_office_mojo[\"Release Group\"] = df_box_office_mojo[\"Release Group\"].str.lower()\\\n",
    "#                                            .str.normalize('NFKD')\\\n",
    "#                                            .str.encode('ascii', errors='ignore')\\\n",
    "#                                            .str.decode('utf-8')\\\n",
    "#                                            .str.replace(\" \", \"_\", regex=True)\\\n",
    "#                                            .str.replace(\"\\W\", \"\", regex=True)\n",
    "#     df_box_office_mojo.drop(['%', '%.1'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#     df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "#     df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "#     # df_incl_exog.info()\n",
    "\n",
    "\n",
    "#     df_incl_exog[\"oscar_noms\"] = oscar_noms\n",
    "#     df_incl_exog[\"oscar_wins\"] = oscar_wins\n",
    "\n",
    "#     df_incl_exog = df_incl_exog.reset_index().merge(df_box_office_mojo, left_on=['primaryTitleFormatted', 'Year'], right_on=['Release Group', 'year'], how=\"left\").set_index('id')\n",
    "#     df_incl_exog.drop(['Release Group', 'year'], axis=1, inplace=True)\n",
    "\n",
    "#     df_incl_exog.loc[df_incl_exog['Worldwide'] == '-', 'Worldwide'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Domestic'] == '-', 'Domestic'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Foreign'] == '-', 'Foreign'] = np.nan\n",
    "#     df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'] = df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "#     df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'] = df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "#     df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'] = df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "\n",
    "\n",
    "#     df_incl_exog = create_remake_column(df_incl_exog)\n",
    "\n",
    "#     # # add the language of the original title, currently commented for training data usage and not wait 15 min every time\n",
    "#     # df_incl_exog = add_language_of_original_title(df_incl_exog)\n",
    "\n",
    "#     df_added_lang = pd.read_csv('additional_data/df_added_lang.csv', index_col=0)\n",
    "#     df_added_lang = df_added_lang.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "#     df_incl_exog = df_incl_exog.join(df_added_lang['title_language'], how='left')\n",
    "\n",
    "#     df_incl_exog = add_english_title_or_not(df_incl_exog)\n",
    "#     df_incl_exog = add_movie_genre(df_incl_exog)\n",
    "#     df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T\n",
    "#     df_incl_exog.to_csv(f\"{filename}_df_with_features.csv\")\n",
    "    \n",
    "#     return df_incl_exog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c43d4-36ac-4082-a627-22f2f6e2ef5b",
   "metadata": {},
   "source": [
    "# Evaluating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cfad8-1582-4616-9bf3-677c07c39df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                                learning_rate=0.01,\n",
    "                                num_iterations=1000,\n",
    "                                feature_fraction=0.8,\n",
    "                                verbosity=1,\n",
    "                                random_state=17)\n",
    "model_lgbm.fit(train_df_prepped.loc[:, train_df_prepped.columns != 'label'],\n",
    "              train_df_prepped['label'],\n",
    "              eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9e8f9-2472-44bb-a561-16b23cfe4c63",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ba9ca",
   "metadata": {},
   "source": [
    "## Add and process train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df_processor_enrichment('validation_hidden.csv')\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_prepped = df_model_prep(valid_df, 'valid')\n",
    "valid_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_processor_enrichment('test_hidden.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_prepped = df_model_prep(test_df, 'test')\n",
    "test_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8259cc-1bc6-4447-8d9e-7cf00d9bc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_lgbm = model_lgbm.predict(valid_df_prepped)\n",
    "test_preds_lgbm = model_lgbm.predict(test_df_prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in val_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in test_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
