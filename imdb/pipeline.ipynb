{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "from py_files.load_box_office_data import load_and_aggregate_box_office\n",
    "from py_files.add_remake_feature import create_remake_column\n",
    "from py_files.add_langoriginaltitle_feature import add_language_of_original_title\n",
    "from py_files.add_ENvsNonEN_feature import add_english_title_or_not\n",
    "from py_files.add_movie_genre_feature import add_movie_genre\n",
    "from py_files.df_processor_enrichment import df_processor_enrichment\n",
    "\n",
    "from py_files.df_model_prep import df_model_prep\n",
    "from py_files.d2v_embed import d2v_embed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_files.load_original_data import load_original_data\n",
    "\n",
    "df_original = load_original_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the dataframe so we leave the original untouched\n",
    "df_preprocessed = df_original.copy(deep=True)\n",
    "\n",
    "# start the preprocessing\n",
    "df_preprocessed = df_original.replace(\"\\\\N\", np.nan)\n",
    "df_preprocessed[\"primaryTitleFormatted\"] = df_preprocessed[\"primaryTitle\"].str.lower()\\\n",
    "                                                                          .str.normalize('NFKD')\\\n",
    "                                                                          .str.encode('ascii', errors='ignore')\\\n",
    "                                                                          .str.decode('utf-8')\\\n",
    "                                                                          .str.replace(\" \", \"_\", regex=True)\\\n",
    "                                                                          .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "# merge endYear into beginYear when beginYear is not available --> rename Year\n",
    "df_preprocessed = merge_start_end_year(df_preprocessed)\n",
    "\n",
    "# set the datatypes of the dataframe correctly\n",
    "df_preprocessed['Year'] = df_preprocessed['Year'].astype(int)\n",
    "df_preprocessed['runtimeMinutes'] = df_preprocessed['runtimeMinutes'].astype(float)\n",
    "\n",
    "df_preprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscars = pd.read_csv(\"additional_data/oscars.csv\")\n",
    "\n",
    "oscars[\"film\"] = oscars[\"film\"].str.lower()\\\n",
    "                               .str.normalize('NFKD')\\\n",
    "                               .str.encode('ascii', errors='ignore')\\\n",
    "                               .str.decode('utf-8')\\\n",
    "                               .str.replace(\" \", \"_\", regex=True)\\\n",
    "                               .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "# Counting oscar nominations and wins per movie\n",
    "oscar_noms = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].count()\n",
    "oscar_wins = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writer and Director data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writers = writer_director_to_one_hot(\"writers\")\n",
    "directors = writer_director_to_one_hot(\"directors\")\n",
    "written_and_directed = writers.add(directors, fill_value=0).fillna(0).astype(int).loc[df_preprocessed[\"tconst\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB = pd.read_csv(\"additional_data/TMDB.csv\")[[\"budget\", \"genres\", \"imdb_id\", \n",
    "                                                   \"original_language\", \"overview\", \n",
    "                                                   \"popularity\", \"production_companies\", \n",
    "                                                   \"tagline\", \"Keywords\", \"revenue\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_list(dictionary):\n",
    "    try:\n",
    "        d = ast.literal_eval(dictionary)\n",
    "    except ValueError:\n",
    "        return []\n",
    "    \n",
    "    return [i[\"name\"] for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TMDB[\"genres\"] = df_TMDB[\"genres\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"Keywords\"] = df_TMDB[\"Keywords\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB[\"production_companies\"] = df_TMDB[\"production_companies\"].apply(lambda x: dict_to_list(x))\n",
    "df_TMDB = df_TMDB.set_index(\"imdb_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metacritic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"additional_data/Metacritic.csv\").drop(\"Unnamed: 0\", axis=1).set_index(\"movie\")\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: eval(x))\n",
    "df_meta[\"overview\"] = df_meta[\"overview\"].apply(lambda x: x[0] if x else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine overviews\n",
    "overviews = pd.merge(df_TMDB[\"overview\"], df_meta[\"overview\"], left_index=True, right_index=True, how=\"outer\")\n",
    "overviews[\"overview\"] = overviews[\"overview_x\"].str.cat(overviews[\"overview_y\"], na_rep=\"\")\n",
    "overviews = overviews.drop([\"overview_x\", \"overview_y\"], axis=1)\n",
    "df_TMDB = df_TMDB.drop(\"overview\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Office data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_office_mojo = load_and_aggregate_box_office()\n",
    "\n",
    "# process the 'release group' (read movie title) in the same way as the formatted title\n",
    "df_box_office_mojo[\"Release Group\"] = df_box_office_mojo[\"Release Group\"].str.lower()\\\n",
    "                                       .str.normalize('NFKD')\\\n",
    "                                       .str.encode('ascii', errors='ignore')\\\n",
    "                                       .str.decode('utf-8')\\\n",
    "                                       .str.replace(\" \", \"_\", regex=True)\\\n",
    "                                       .str.replace(\"\\W\", \"\", regex=True)\n",
    "df_box_office_mojo.drop(['%', '%.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding of exogenous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "df_incl_exog.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog[\"oscar_noms\"] = oscar_noms\n",
    "df_incl_exog[\"oscar_wins\"] = oscar_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add mojo box office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = df_incl_exog.reset_index().merge(df_box_office_mojo, left_on=['primaryTitleFormatted', 'Year'], right_on=['Release Group', 'year'], how=\"left\").set_index('id')\n",
    "df_incl_exog.drop(['Release Group', 'year'], axis=1, inplace=True)\n",
    "\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'] == '-', 'Worldwide'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'] == '-', 'Domestic'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'] == '-', 'Foreign'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'] = df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'] = df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'] = df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'].apply(lambda x: float(x.replace('$', '').replace(',', '')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add remake column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = create_remake_column(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the language of the original title, currently commented for training data usage and not wait 15 min every time\n",
    "# df_incl_exog = add_language_of_original_title(df_incl_exog)\n",
    "\n",
    "df_added_lang = pd.read_csv('additional_data/df_added_lang.csv', index_col=0)\n",
    "df_added_lang = df_added_lang.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "df_incl_exog = df_incl_exog.join(df_added_lang['title_language'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add whether title is English or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = add_english_title_or_not(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add movie genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = add_movie_genre(df_incl_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add writers and directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add TMDB & Metacritic overviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = pd.merge(df_incl_exog, df_TMDB, how=\"left\", left_index=True, right_index=True)\n",
    "df_incl_exog = pd.merge(df_incl_exog, overviews, how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save dataframe with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_incl_exog.to_csv('df_with_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert non-numeric columns to numeric.\n",
    "We use Doc2Vec to embed each string column into n-by-128 array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from py_files.df_processor_enrichment import df_processor_enrichment\n",
    "# train_df = pd.read_csv('df_with_features.csv', index_col=0)\n",
    "train_df = df_processor_enrichment('train')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"startYear\"] = train_df[\"startYear\"].astype(float)\n",
    "train_df[\"endYear\"] = train_df[\"endYear\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from py_files.df_model_prep import df_model_prep\n",
    "\n",
    "train_df_prepped = df_model_prep(train_df,'train')\n",
    "train_df_prepped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                                learning_rate=0.01,\n",
    "                                num_iterations=1000,\n",
    "                                feature_fraction=0.8,\n",
    "                                verbosity=1,\n",
    "                                random_state=17)\n",
    "model_lgbm.fit(train_df_prepped.loc[:, train_df_prepped.columns != 'label'],\n",
    "              train_df_prepped['label'],\n",
    "              eval_metric='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and process train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df_processor_enrichment('validation_hidden.csv')\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df[\"startYear\"] = train_df[\"startYear\"].astype(float)\n",
    "valid_df[\"endYear\"] = train_df[\"endYear\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_prepped = df_model_prep(valid_df, 'valid')\n",
    "valid_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_df_prepped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_processor_enrichment('test_hidden.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_prepped = df_model_prep(test_df, 'test')\n",
    "test_df_prepped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_prepped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_lgbm = model_lgbm.predict(valid_df_prepped)\n",
    "test_preds_lgbm = model_lgbm.predict(test_df_prepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in val_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds_lgbm.txt', 'w+') as f:\n",
    "    for val in test_preds_lgbm:\n",
    "        f.write(f\"{str(val)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
