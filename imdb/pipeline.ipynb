{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2eb797-3622-422f-97df-95f6f4f454fb",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8c3a4e-d01b-4874-908d-ec2d1cf22b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "\n",
    "from py_files.writer_director_to_one_hot import writer_director_to_one_hot\n",
    "from py_files.add_merge_begin_end_year import merge_start_end_year\n",
    "from py_files.load_box_office_data import load_and_aggregate_box_office\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59816f3-b00d-4d73-bf8c-401c9a528c99",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7dcbe7-3de0-4f9d-b1f9-23a235d489cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: train-8.csv, train-2.csv, train-7.csv, train-5.csv, train-3.csv, train-4.csv, train-1.csv, train-6.csv\n"
     ]
    }
   ],
   "source": [
    "from py_files.load_original_data import load_original_data\n",
    "\n",
    "df_original = load_original_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8291b2d-ad58-4477-9e9d-8cf717f95f0f",
   "metadata": {},
   "source": [
    "# Preprocessing of original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bae9711c-aa48-485b-9093-f142059703d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7959 entries, 0 to 7958\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   tconst                 7959 non-null   object \n",
      " 1   primaryTitle           7959 non-null   object \n",
      " 2   originalTitle          3971 non-null   object \n",
      " 3   startYear              7173 non-null   object \n",
      " 4   endYear                786 non-null    object \n",
      " 5   runtimeMinutes         7946 non-null   float64\n",
      " 6   numVotes               7169 non-null   float64\n",
      " 7   label                  7959 non-null   bool   \n",
      " 8   primaryTitleFormatted  7959 non-null   object \n",
      " 9   Year                   7959 non-null   int64  \n",
      "dtypes: bool(1), float64(2), int64(1), object(6)\n",
      "memory usage: 567.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# copy the dataframe so we leave the original untouched\n",
    "df_preprocessed = df_original.copy(deep=True)\n",
    "\n",
    "# start the preprocessing\n",
    "df_preprocessed = df_original.replace(\"\\\\N\", np.nan)\n",
    "df_preprocessed[\"primaryTitleFormatted\"] = df_preprocessed[\"primaryTitle\"].str.lower()\\\n",
    "                                                                          .str.normalize('NFKD')\\\n",
    "                                                                          .str.encode('ascii', errors='ignore')\\\n",
    "                                                                          .str.decode('utf-8')\\\n",
    "                                                                          .str.replace(\" \", \"_\", regex=True)\\\n",
    "                                                                          .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "# merge endYear into beginYear when beginYear is not available --> rename Year\n",
    "df_preprocessed = merge_start_end_year(df_preprocessed)\n",
    "\n",
    "# set the datatypes of the dataframe correctly\n",
    "df_preprocessed['Year'] = df_preprocessed['Year'].astype(int)\n",
    "df_preprocessed['runtimeMinutes'] = df_preprocessed['runtimeMinutes'].astype(float)\n",
    "\n",
    "df_preprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13628a1-7394-4a0f-bf00-8ea7ce5f8a26",
   "metadata": {},
   "source": [
    "## Preprocessing of exogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a5e9f-6bbc-4094-b30d-79eedc0e9613",
   "metadata": {},
   "source": [
    "### Oscar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ec5f29-a1a8-4dbe-9d38-ea74c40891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "oscars = pd.read_csv(\"additional_data/oscars.csv\")\n",
    "\n",
    "oscars[\"film\"] = oscars[\"film\"].str.lower()\\\n",
    "                               .str.normalize('NFKD')\\\n",
    "                               .str.encode('ascii', errors='ignore')\\\n",
    "                               .str.decode('utf-8')\\\n",
    "                               .str.replace(\" \", \"_\", regex=True)\\\n",
    "                               .str.replace(\"\\W\", \"\", regex=True)\n",
    "\n",
    "# Counting oscar nominations and wins per movie\n",
    "oscar_noms = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].count()\n",
    "oscar_wins = pd.merge(df_preprocessed, oscars, left_on = \"primaryTitleFormatted\", right_on = \"film\").groupby(\"tconst\")[\"winner\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f1da1-6a79-4b57-9eb3-87796ce460e2",
   "metadata": {},
   "source": [
    "### Writer and Director data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3549ed24-a788-4a2d-80b3-1e26ebbefd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find writers and directors per movie and combine the two\n",
    "written_and_directed = (writer_director_to_one_hot(\"writers\") + writer_director_to_one_hot(\"directors\")).fillna(0).astype(int).loc[df_preprocessed['tconst']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb61c28-a98e-49a3-ae69-6a505c193f84",
   "metadata": {},
   "source": [
    "### TMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb9dfd-13ae-4ecf-8a1e-90236bf4767e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82526bd3-364f-4db2-919f-1e9a9c90ef31",
   "metadata": {},
   "source": [
    "### Box Office data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ab0f07-c114-4741-8ba1-5b162676582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: box_office_mojo/2014.csv, box_office_mojo/1982.csv, box_office_mojo/1979.csv, box_office_mojo/1980.csv, box_office_mojo/2008.csv, box_office_mojo/1997.csv, box_office_mojo/2015.csv, box_office_mojo/1986.csv, box_office_mojo/2010.csv, box_office_mojo/1978.csv, box_office_mojo/1996.csv, box_office_mojo/2011.csv, box_office_mojo/1998.csv, box_office_mojo/2009.csv, box_office_mojo/2005.csv, box_office_mojo/2018.csv, box_office_mojo/1977.csv, box_office_mojo/1981.csv, box_office_mojo/1994.csv, box_office_mojo/2013.csv, box_office_mojo/2002.csv, box_office_mojo/2006.csv, box_office_mojo/1991.csv, box_office_mojo/1985.csv, box_office_mojo/2017.csv, box_office_mojo/1984.csv, box_office_mojo/1995.csv, box_office_mojo/2016.csv, box_office_mojo/2001.csv, box_office_mojo/2007.csv, box_office_mojo/1989.csv, box_office_mojo/1988.csv, box_office_mojo/2012.csv, box_office_mojo/2000.csv, box_office_mojo/1990.csv, box_office_mojo/2004.csv, box_office_mojo/2021.csv, box_office_mojo/2022.csv, box_office_mojo/2020.csv, box_office_mojo/1999.csv, box_office_mojo/2019.csv, box_office_mojo/1983.csv, box_office_mojo/2003.csv, box_office_mojo/1993.csv, box_office_mojo/1987.csv, box_office_mojo/1992.csv\n"
     ]
    }
   ],
   "source": [
    "df_box_office_mojo = load_and_aggregate_box_office()\n",
    "\n",
    "# process the 'release group' (read movie title) in the same way as the formatted title\n",
    "df_box_office_mojo[\"Release Group\"] = df_box_office_mojo[\"Release Group\"].str.lower()\\\n",
    "                                       .str.normalize('NFKD')\\\n",
    "                                       .str.encode('ascii', errors='ignore')\\\n",
    "                                       .str.decode('utf-8')\\\n",
    "                                       .str.replace(\" \", \"_\", regex=True)\\\n",
    "                                       .str.replace(\"\\W\", \"\", regex=True)\n",
    "df_box_office_mojo.drop(['%', '%.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2446b69-5867-4d66-9df7-03da9d2559d4",
   "metadata": {},
   "source": [
    "# Adding of exogenous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b46bee7-f2ac-4c41-ba16-8f62ae993999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incl_exog = df_preprocessed.copy(deep=True)\n",
    "df_incl_exog = df_incl_exog.rename({\"tconst\" : \"id\"}, axis = 1).set_index(\"id\")\n",
    "\n",
    "# add oscar data\n",
    "df_incl_exog[\"oscar_noms\"] = oscar_noms\n",
    "df_incl_exog[\"oscar_wins\"] = oscar_wins\n",
    "\n",
    "# add writers and directors\n",
    "df_incl_exog = pd.concat([df_incl_exog.T, written_and_directed.T]).T\n",
    "\n",
    "# add mojo box office values\n",
    "df_incl_exog = pd.merge(df_incl_exog, df_box_office_mojo, left_on=['primaryTitleFormatted', 'Year'], right_on=['Release Group', 'year'], how='left')\n",
    "df_incl_exog.drop(['Release Group', 'year'], axis=1, inplace=True)\n",
    "\n",
    "## set unknown values to np.nan and make the box office dollars into actual numbers\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'] == '-', 'Worldwide'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'] == '-', 'Domestic'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'] == '-', 'Foreign'] = np.nan\n",
    "df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'] = df_incl_exog.loc[df_incl_exog['Worldwide'].notnull(), 'Worldwide'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'] = df_incl_exog.loc[df_incl_exog['Domestic'].notnull(), 'Domestic'].apply(lambda x: float(x.replace('$', '').replace(',', '')))\n",
    "df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'] = df_incl_exog.loc[df_incl_exog['Foreign'].notnull(), 'Foreign'].apply(lambda x: float(x.replace('$', '').replace(',', '')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd196bd-d145-4a63-a431-219af524380e",
   "metadata": {},
   "source": [
    "# Selecting data for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438a851-1415-4118-9e35-a1fe5e4c59d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a3e00b-bc50-485b-8ab0-00183a6bb9d8",
   "metadata": {},
   "source": [
    "df_added_dataclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc0ce7-1f2a-49b7-8643-e666c23fda45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01c43d4-36ac-4082-a627-22f2f6e2ef5b",
   "metadata": {},
   "source": [
    "# Evaluating classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3cfad8-1582-4616-9bf3-677c07c39df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ca9e8f9-2472-44bb-a561-16b23cfe4c63",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8259cc-1bc6-4447-8d9e-7cf00d9bc89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
